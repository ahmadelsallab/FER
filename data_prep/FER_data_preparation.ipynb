{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_data_preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMxvY6q4kJO",
        "colab_type": "text"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rFeCUWhc5g4i",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2\n",
        "import csv\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8nW3k7VAN1P",
        "colab_type": "text"
      },
      "source": [
        "### **Preprocessing**\n",
        "##Iterate over frames in each video to:\n",
        "1. Crop the face using haarcascade face detector.\n",
        "2. Calculate flow between each two consecutive frames\n",
        "3. Save the cropped image and the flow image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp0Et3X96Mmq",
        "colab_type": "code",
        "outputId": "5a8f8731-a172-4f08-e59d-fc4370e8555a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "home_dir = '/content/drive/My Drive/Colab Notebooks/FER/'\n",
        "baum_dir = home_dir + 'BAUM/'\n",
        "temp_image = np.array([])\n",
        "none_image = None\n",
        "\n",
        "videos = glob.glob(baum_dir + 'BAUM1s_MP4 - All/*/*.mp4')\n",
        "videos = sorted(videos)\n",
        "print(len(videos), \" videos was detected in baum_dir\")\n",
        "\n",
        "\n",
        "# Create a face detec tion module \n",
        "calssifiers =['haarcascade_frontalface_default.xml',\n",
        "              'haarcascade_frontalface_alt2.xml',\n",
        "              'haarcascade_frontalcatface_extended.xml',\n",
        "              'haarcascade_frontalcatface.xml',\n",
        "              'haarcascade_frontalface_alt_tree.xml',\n",
        "              'haarcascade_frontalface_alt.xml']\n",
        "\n",
        "def detectFace(img):\n",
        "    for classifier in calssifiers:\n",
        "        face_cascade = cv2.CascadeClassifier(home_dir +'face_detectors/' + classifier)\n",
        "        faces = face_cascade.detectMultiScale(img, 1.3, 1)\n",
        "        if (len(faces) > 0):\n",
        "            return faces\n",
        "    faces = []\n",
        "    return faces"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "1198  videos was detected in baum_dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y09xOeFOGELD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stamp = str(time.time()).split('.')[0]\n",
        "csv_file_name = 'data_' + stamp +\".csv\"\n",
        "#csv_file_name = baum_dir + csv_file_name\n",
        "#print (\"Target scv file is: \", csv_file_name)\n",
        "\n",
        "data_generated = 0\n",
        "if not data_generated:\n",
        "  #data_frame = pd.DataFrame([[\"flow\", \"spatial\",  \"emotion\", \"code\"]])\n",
        "  #data_frame.to_csv(csv_file_name, mode='w', header=False, index = False, sep = ',')\n",
        "  data_labels_xl =  pd.read_excel(baum_dir +\"Annotations_BAUM1s.xlsx\")\n",
        "  target_codes = [1, 6, 7, 10, 11, 8]\n",
        "  data_labels = np.array(data_labels_xl)\n",
        "\n",
        "  videoSkipped = 0\n",
        "  allbadFrames_count = 0\n",
        "  videoProcessed = 0\n",
        "  for video in videos:\n",
        "      # Test if this video has been already procedded\n",
        "      already_processed = 0\n",
        "      flow_path = video.replace('BAUM1s_MP4 - All', 'imgs_flow').replace('.mp4', '/')\n",
        "      spatial_path = video.replace('BAUM1s_MP4 - All', 'imgs_spatial').replace('.mp4', '/')\n",
        "      flow_relative_path = flow_path.split('/')[-4] + '/' + flow_path.split('/')[-3] + '/' + flow_path.split('/')[-2] \n",
        "      spatial_relative_path = spatial_path.split('/')[-4] + '/' + spatial_path.split('/')[-3] + '/' + spatial_path.split('/')[-2]\n",
        "      folder = baum_dir + spatial_relative_path\n",
        "      contents = glob.glob(folder + \"/\" + \"*.png\")\n",
        "      data_count = len(contents)\n",
        "      if  data_count > 15:\n",
        "          already_processed = 1\n",
        "\n",
        "      # Test if this video in one of the 6 classes\n",
        "      sample_name = video.split('/')[-1].split('.')[0]\n",
        "      label_found = 0\n",
        "      for label in data_labels:\n",
        "        if label[3] == sample_name:\n",
        "            emotion = label[4]\n",
        "            code = label[5]\n",
        "            if code in target_codes:\n",
        "              label_found = 1\n",
        "              break\n",
        "\n",
        "      if (not label_found) or (already_processed):\n",
        "        pass #print(\"already processed or out of classes\")\n",
        "      else:\n",
        "        #print(video)\n",
        "        videoProcessed += 1\n",
        "        cap = cv2.VideoCapture(video)\n",
        "        no_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  \n",
        "        ret, old_frame = cap.read()\n",
        "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        faces = detectFace(old_gray)\n",
        "        count = 0\n",
        "        while (len(faces) == 0):    \n",
        "            if count > no_of_frames - 1: #Stop looking for a valid frame at the end of the video #\n",
        "                break\n",
        "            count+=1\n",
        "            #print(\"First Frame is not good for face detection \", count, no_of_frames)\n",
        "            ret, old_frame = cap.read()\n",
        "            if isinstance(old_frame, type(temp_image)) and not isinstance(old_frame, type(none_image)) :\n",
        "                old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "                faces = detectFace(old_gray)\n",
        "            else:\n",
        "                print (\"bad frame\", type(old_frame), video)\n",
        "                \n",
        "                      \n",
        "        if (len(faces) == 0):\n",
        "            print (\"All Video Frames are BAD\", video)\n",
        "            videoSkipped += 1\n",
        "            continue\n",
        "        \n",
        "        (x,y,w,h) = faces[0]\n",
        "        old_gray = old_gray[y:y+h, x:x+w]\n",
        "        old_color = old_frame[y:y+h, x:x+w]\n",
        "        size_gray = old_gray.shape\n",
        "        size_color = old_color.shape\n",
        "\n",
        "        # Create a mask image for drawing purposes\n",
        "        mask = np.zeros_like(old_color)\n",
        "        hsv = np.zeros_like(old_color)\n",
        "        hsv[...,1] = 255\n",
        "        \n",
        "        noFacesCnt = 0\n",
        "        calcOpticalFlow = 0\n",
        "        for i in range(no_of_frames - 1):\n",
        "            ret,frame = cap.read()\n",
        "            if isinstance(frame, type(temp_image)) and not isinstance(frame, type(none_image)) :\n",
        "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                faces = detectFace(frame_gray)\n",
        "                if len(faces) == 0:\n",
        "                    calcOpticalFlow = 0\n",
        "                    noFacesCnt += 1\n",
        "                    allbadFrames_count +=1\n",
        "                    #print (\"No Faces Found \", noFacesCnt, no_of_frames, video)\n",
        "                    continue\n",
        "                \n",
        "                (x,y,w,h)  = faces[0]\n",
        "                frame_gray = frame_gray[y:y+h, x:x+w]\n",
        "                roi_color = frame[y:y+h, x:x+w]\n",
        "                \n",
        "                if(frame_gray.shape[0] < 90 or roi_color.shape[0] < 90 ):\n",
        "                    calcOpticalFlow = 0\n",
        "                    allbadFrames_count +=1\n",
        "                    #print(\"Skip this frame , small image!! \", video , i)\n",
        "                    continue\n",
        "                                \n",
        "                #print(frame_gray.shape)\n",
        "                frame_gray = cv2.resize(frame_gray, (size_gray[1],size_gray[0]))\n",
        "                roi_color = cv2.resize(roi_color, (size_color[1],size_color[0]))\n",
        "                #print(frame_gray.shape, \"after\")\n",
        "              \n",
        "                calcOpticalFlow += 1\n",
        "                            \n",
        "                if (calcOpticalFlow > 1):\n",
        "                    flow = cv2.calcOpticalFlowFarneback(old_gray,frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)            \n",
        "                    mag, ang   = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "                    hsv[...,0] = ang*180/np.pi/2\n",
        "                    hsv[...,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "                    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "                    \n",
        "                    str_i = '{:03}'.format(i) # max 999 frames\n",
        "\n",
        "                    flow_relative_name = flow_relative_path + '/' + str_i + '.png'\n",
        "                    spatial_relative_name = spatial_relative_path + '/' + str_i + '.png'\n",
        "                    \n",
        "                    flow_name_abs = baum_dir + flow_relative_name\n",
        "                    spatial_name_abs = baum_dir + spatial_relative_name\n",
        "\n",
        "                    flow_folder = flow_name_abs.replace('/'+str_i+'.png', '')\n",
        "                    spatial_folder = spatial_name_abs.replace('/'+str_i+'.png', '')\n",
        "\n",
        "                    if not os.path.isdir(flow_folder):\n",
        "                        os.makedirs(flow_folder)\n",
        "                    if not os.path.isdir(spatial_folder):\n",
        "                        print(\"create folder: \", spatial_folder)\n",
        "                        os.makedirs(spatial_folder)\n",
        "                    \n",
        "                    cv2.imwrite(flow_name_abs, rgb)\n",
        "                    cv2.imwrite(spatial_name_abs,roi_color)\n",
        "                    print(\"write Image to directory\", video)\n",
        "                    #data_frame =  pd.DataFrame([[flow_relative_name, spatial_relative_name,  emotion, str(code)]])\n",
        "                    #data_frame.to_csv(csv_file_name, mode='a', header=False, index = False, sep = ',')\n",
        "                        \n",
        "                # Now update the previous frame and previous points\n",
        "                old_gray = frame_gray.copy()\n",
        "              \n",
        "  print(\"No of skipped videos is: \", videoSkipped)\n",
        "  print(\"No of allbadFrames is: \", allbadFrames_count)\n",
        "  print(\"No of video processed is \", videoProcessed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8ZC5JEvm-2",
        "colab_type": "text"
      },
      "source": [
        "# Get All Written Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04oopLIfvmTV",
        "colab_type": "code",
        "outputId": "fd44c122-ce2a-4628-dd71-b274f7691ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from glob import glob\n",
        "import os, time\n",
        "import pandas as pd\n",
        "\n",
        "home_dir = '/content/drive/My Drive/Colab Notebooks/FER/'\n",
        "baum_dir = home_dir + 'BAUM/'\n",
        "\n",
        "data_labels_xl =  pd.read_excel(baum_dir +\"Annotations_BAUM1s.xlsx\")\n",
        "\n",
        "stamp = str(time.time()).split('.')[0]\n",
        "csv_file_name = 'data_6_classes.csv'\n",
        "csv_file_name = baum_dir + csv_file_name\n",
        "data_frame = pd.DataFrame([[\"flow\", \"spatial\",  \"emotion\", \"code\"]])\n",
        "data_frame.to_csv(csv_file_name, mode='w', header=False, index = False, sep = ',')\n",
        "\n",
        "print (\"Target scv file is: \", csv_file_name)\n",
        "\n",
        "flow = baum_dir + 'imgs_flow/'\n",
        "spatial = baum_dir + 'imgs_spatial/'\n",
        "\n",
        "flowImgs = glob(flow+'*/*/*.png')\n",
        "count = 0\n",
        "for img in flowImgs:\n",
        "    flowImg = img\n",
        "    spatialImg = img.replace('imgs_flow', 'imgs_spatial')\n",
        "    if (os.path.isfile(spatialImg)):\n",
        "        count += 1\n",
        "        vidName = img.split('/')[-2]\n",
        "        vidLabel = str(data_labels_xl.loc[data_labels_xl['Clip Name'] == vidName]['Emotion'].values[0])\n",
        "        vidCode = str(data_labels_xl.loc[data_labels_xl['Clip Name'] == vidName]['Emotion Code'].values[0])\n",
        "        if (int(vidCode) in (1, 10, 11, 6, 7, 8)):\n",
        "            #print ('Needed Emotion')\n",
        "            print (flowImg, spatialImg, vidLabel, vidCode)\n",
        "            data_frame =  pd.DataFrame([[flowImg, spatialImg,  vidLabel, vidCode]])\n",
        "            data_frame.to_csv(csv_file_name, mode='a', header=False, index = False, sep = ',')\n",
        "\n",
        "print (len(flowImgs), count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Target scv file is:  /content/drive/My Drive/Colab Notebooks/FER/BAUM/data_1583416240.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKof7wd-K2G",
        "colab_type": "text"
      },
      "source": [
        "### **Splitting data to train / valid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un7zUkLB-Lgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "home_dir = '/content/drive/My Drive/Colab Notebooks/FER/'\n",
        "baum_dir = home_dir + 'BAUM/'\n",
        "\n",
        "csv_file = 'data_6_classes.csv'\n",
        "data = pd.read_csv(baum_dir + csv_file )\n",
        "data.sort_values(by=['code'])\n",
        "data = np.array(data)\n",
        "\n",
        "training_data = baum_dir + \"training_data.csv\"\n",
        "validation_data = baum_dir + \"validation_data.csv\"\n",
        "\n",
        "\n",
        "data_frame = pd.DataFrame([[\"flow\", \"spatial\",  \"emotion\", \"code\"]])\n",
        "data_frame.to_csv(training_data, mode='w', header=False, index = False, sep = ',')\n",
        "data_frame.to_csv(validation_data, mode='w', header=False, index = False, sep = ',')\n",
        "\n",
        "def write_to_file(seg, valid): \n",
        "    data_frame =  pd.DataFrame([[seg[0], seg[1],  seg[2], seg[3]]])  \n",
        "    if valid:\n",
        "        data_frame.to_csv(validation_data, mode='a', header=False, index = False, sep = ',')\n",
        "    else: \n",
        "        data_frame.to_csv(training_data, mode='a', header=False, index = False, sep = ',')\n",
        "  \n",
        "val = 8 # 7 train to 1 valid\n",
        "last_folder = \"\"   \n",
        "for row in data:\n",
        "    file_name = row[0]\n",
        "    #print(file_name)\n",
        "    folder = file_name.split('/')[-3]\n",
        "    frame = [row[0], row[1], row[2], row[3]]\n",
        " \n",
        "    if ( folder != last_folder ):\n",
        "        val -= 1\n",
        "        if val == 0:\n",
        "            valid = 1\n",
        "            write_to_file(frame, 1)\n",
        "            print(\"valid\")\n",
        "            val = 8\n",
        "        else:\n",
        "            valid = 0\n",
        "            print(\"train\")\n",
        "            write_to_file(frame, 0)\n",
        "    elif valid:\n",
        "        write_to_file(frame, 1)\n",
        "    elif not valid:\n",
        "        write_to_file(frame, 0)\n",
        "    last_folder = folder\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}